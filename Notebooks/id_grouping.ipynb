{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID Grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say you have generated a few datasets with recurrent IDs. <br>\n",
    "For example, you could select a single ID category during dataset generation (e.g. North European + Male + Young) and generate two datasets with 300+ renders, and different camera parameters.<br>\n",
    "The first dataset is called **Far** (the camera is far from the subject) and and the second one is called **Close** (the camera is close).<br>\n",
    "Say that you want to create a new dataset out of **Far** and **Close** that groups the common IDs in both datasets.\n",
    "\n",
    "<img src=\"Images/ID_grouping1.png\"/>\n",
    "<br><br>(Markdown images don't show up on GitHub. To visualize the image, please clone the repository locally)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isdir, join\n",
    "from shutil import copytree\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('../DataLoader')\n",
    "from Dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory reorganization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BASE_DIR** is the directory where the datasets are located.<br>\n",
    "The new dataset directory will be called **Commons IDs** (it will be created automatically under **BASE_DIR**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '../ID_grouping_dataset'\n",
    "DST_DATASET = join(BASE_DIR, 'Common IDs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paths to the datasets we want to group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_paths = [join(BASE_DIR, dir) for dir in sorted(listdir(BASE_DIR)) if isdir(join(BASE_DIR, dir))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a list of IDs in each of the datasets and find out the IDs that appear in all of them. <br>\n",
    "This might take up to a few minutes depending on the number of datasets and their size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking up IDs in dataset: ../ID_grouping_dataset/Far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:05<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking up IDs in dataset: ../ID_grouping_dataset/Near\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:05<00:00,  6.84it/s]\n"
     ]
    }
   ],
   "source": [
    "ids_in_datasets = []\n",
    "\n",
    "for ds_dir in dataset_paths:\n",
    "    print(f'Looking up IDs in dataset: {ds_dir}')\n",
    "    ids_in_datasets += [[]]\n",
    "    ds = Dataset(ds_dir)\n",
    "    for dp in tqdm(ds):\n",
    "        ids_in_datasets[-1] += [dp.identity_id]\n",
    "\n",
    "shared_ids = set(ids_in_datasets[0])\n",
    "for id_list in ids_in_datasets[1:]:\n",
    "    shared_ids = shared_ids.intersection(id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the shared IDs, we create a new subfolder to **Common IDs** that gets a copy of the datapoints from each of the original datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_datasets = len(dataset_paths)\n",
    "for i, id in enumerate(shared_ids):\n",
    "    id_dst_dir = join(DST_DATASET, str(i))\n",
    "    pathlib.Path(id_dst_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for j in range(number_of_datasets):\n",
    "        environment_idx = ids_in_datasets[j].index(id) + 1\n",
    "        environment_dir_name = 'environment_' + str(environment_idx).zfill(5)\n",
    "        environment_path = join(dataset_paths[j], environment_dir_name)\n",
    "        copytree(environment_path, join(id_dst_dir, os.path.basename(dataset_paths[j])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the final result you should get: <br>\n",
    "<img src=\"Images/ID_grouping2.png\"/>\n",
    "<br><br>(Markdown images don't show up on GitHub. To visualize the image, please clone the repository locally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e1793042832798f48320599fe96661a3f5ff655e48dbc8746c0b01742b1b00fc"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
