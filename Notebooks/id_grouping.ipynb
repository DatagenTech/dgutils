{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID Grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook's purpose is to explain how to take a large dataset with recurrent IDs and reorganize it into a new dataset with similar IDs grouped together.<br><br>\n",
    "Please note that unlike the other notebooks, this notebook <b>cannot</b> be run on the datasets we provide in the repository. The reason is that the datasets are too small and don't include recurrent IDs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from shutil import copytree\n",
    "import pathlib\n",
    "import datagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory reorganization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BASE_DIR** is the directory where your datasets is located.<br>\n",
    "The new dataset directory will be called **Grouped** (it will be created automatically under **BASE_DIR**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '.'\n",
    "SRC_DATASET = join(BASE_DIR, 'Data')\n",
    "DST_DATASET = join(BASE_DIR, 'Grouped')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iterate over all the datapoints in the dataset, check their IDs, and copy them into the new dataset, under the relevant ID folders. <br>\n",
    "This might take a few minutes depending on the dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datagen.load(SRC_DATASET)\n",
    "\n",
    "for i, dp in enumerate(ds):\n",
    "    # Look up the datapoint ID\n",
    "    identity = dp.actor_metadata.identity_id\n",
    "    \n",
    "    # Create a new folder for this ID if it doesn't exist already\n",
    "    id_dst_path = join(DST_DATASET, str(identity))\n",
    "    pathlib.Path(id_dst_path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Find out the current environment path\n",
    "    env_dir_name = 'environment_' + str(i + 1).zfill(5)\n",
    "    env_path = join(SRC_DATASET, env_dir_name)\n",
    "    \n",
    "    # Copy the current environment folder to the new dataset\n",
    "    copytree(env_path, join(id_dst_path, env_dir_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new dataset is now ready! You can find it under **BASE_DIR**"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e1793042832798f48320599fe96661a3f5ff655e48dbc8746c0b01742b1b00fc"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
